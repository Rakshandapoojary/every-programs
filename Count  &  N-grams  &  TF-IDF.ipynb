{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87393d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also', 'boy', 'chirag', 'he', 'is', 'person', 'she', 'smart']\n",
      "[[1 1 0 1 2 0 1 2]\n",
      " [0 0 1 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sents=['He is a smart boy.she is also smart',\n",
    "       'chirag is a smart person']\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(sents)\n",
    "x=x.toarray()\n",
    "vocabulary=sorted(cv.vocabulary_.keys())\n",
    "print(vocabulary)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b706e",
   "metadata": {},
   "source": [
    "# N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42222f6c",
   "metadata": {},
   "source": [
    "# 1) bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9bda1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also smart', 'boy she', 'chirag is', 'he is', 'is also', 'is smart', 'she is', 'smart boy', 'smart person']\n",
      "[[1 1 0 1 1 1 1 1 0]\n",
      " [0 0 1 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sents=['He is a smart boy.she is also smart',\n",
    "       'chirag is a smart person']\n",
    "cv=CountVectorizer(ngram_range=(2,2))\n",
    "x=cv.fit_transform(sents)\n",
    "x=x.toarray()\n",
    "vocabulary=sorted(cv.vocabulary_.keys())\n",
    "print(vocabulary)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb280b",
   "metadata": {},
   "source": [
    "# 2) tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60292d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boy she is', 'chirag is smart', 'he is smart', 'is also smart', 'is smart boy', 'is smart person', 'she is also', 'smart boy she']\n",
      "[[1 0 1 1 1 0 1 1]\n",
      " [0 1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sents=['He is a smart boy.she is also smart',\n",
    "       'chirag is a smart person']\n",
    "cv=CountVectorizer(ngram_range=(3,3))\n",
    "x=cv.fit_transform(sents)\n",
    "x=x.toarray()\n",
    "vocabulary=sorted(cv.vocabulary_.keys())\n",
    "print(vocabulary)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c046c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ad2880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boy she is also', 'chirag is smart person', 'he is smart boy', 'is smart boy she', 'she is also smart', 'smart boy she is']\n",
      "[[1 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sents=['He is a smart boy.she is also smart',\n",
    "       'chirag is a smart person']\n",
    "cv=CountVectorizer(ngram_range=(4,4))\n",
    "x=cv.fit_transform(sents)\n",
    "x=x.toarray()\n",
    "vocabulary=sorted(cv.vocabulary_.keys())\n",
    "print(vocabulary)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfeec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd1f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boy she is also smart', 'he is smart boy she', 'is smart boy she is', 'smart boy she is also']\n",
      "[[1 1 1 1]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sents=['He is a smart boy.she is also smart',\n",
    "       'chirag is a smart person']\n",
    "cv=CountVectorizer(ngram_range=(5,5))\n",
    "x=cv.fit_transform(sents)\n",
    "x=x.toarray()\n",
    "vocabulary=sorted(cv.vocabulary_.keys())\n",
    "print(vocabulary)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0242902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a8808c",
   "metadata": {},
   "source": [
    "# TF-IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f367a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>infectious</th>\n",
       "      <td>0.490479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highly</th>\n",
       "      <td>0.490479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.490479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>0.373022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disease</th>\n",
       "      <td>0.373022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>older</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pepole</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afect</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>due</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TF-IDF\n",
       "infectious   0.490479\n",
       "highly       0.490479\n",
       "is           0.490479\n",
       "coronavirus  0.373022\n",
       "disease      0.373022\n",
       "older        0.000000\n",
       "this         0.000000\n",
       "the          0.000000\n",
       "risk         0.000000\n",
       "pepole       0.000000\n",
       "afect        0.000000\n",
       "most         0.000000\n",
       "are          0.000000\n",
       "high         0.000000\n",
       "due          0.000000\n",
       "at           0.000000\n",
       "to           0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sents=['coronavirus is a highly infectious disease',\n",
    "      'coronavirus afect the older pepole most',\n",
    "      'older pepole are at high risk due to this  disease']\n",
    "tfidf= TfidfVectorizer()\n",
    "transformed = tfidf.fit_transform(sents)\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(transformed[0].T.todense(),\n",
    "               index=tfidf.get_feature_names_out(),\n",
    "               columns=[\"TF-IDF\"])\n",
    "df=df.sort_values(\"TF-IDF\",ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5671d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
